{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be31a12-9303-4734-bc3b-b751116987cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6ad47c-558d-4093-be08-ef57dfa72a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef89d78-cd95-44ba-b7a1-22abfc2aabb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dic = {'surprise': 0.37850767, 'x1': 86, 'x10': 128, 'x8': 255}\n",
    "df = pd.DataFrame(dic, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ddb39-992a-42a1-8295-8d76002c934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp analyze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6aa485-18b0-45c3-9762-9b1e85f40f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import defaultPose\n",
    "import numpy as np\n",
    "\n",
    "for target_emotion in 'anger, disgust, fear, happiness, sadness, surprise'.split(', '):\n",
    "    # target_emotion = 'anger'\n",
    "    baseline=defaultPose.prototypeFacialExpressions[target_emotion]\n",
    "    neutral_baseline = defaultPose.prototypeFacialExpressions[\"netural\"]\n",
    "    subtract = abs(np.array(neutral_baseline) - np.array(baseline))\n",
    "    probe_param = {}\n",
    "    for i in range(len(subtract)):\n",
    "        if subtract[i] != 0:\n",
    "            probe_param[\"x{}\".format(i+1)] = subtract[i]\n",
    "    print(\"if target_emotion == '{}':\".format(target_emotion))\n",
    "    print('# {}'.format(target_emotion))\n",
    "    print('optimizer.probe(params=' + str(probe_param) + ', lazy=True,)')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e1ca69-9e7d-4fa4-803c-7ea27a3850e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize_robotParams\n",
      "\n",
      "\n",
      "Smoothly execution activated\n",
      "return_to_stable_state, self.robotParams are all set\n",
      "self.lastState [64, 64, 128, 128, 128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 128, 128, 128, 0]\n",
      "self.nextState [0, 0, 128, 128, 128, 0, 0, 255, 0, 128, 0, 255, 0, 128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 122]\n",
      "Smoothly execution activated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return to StandardPose\n",
    "import RCSystem\n",
    "import defaultPose\n",
    "rb = RCSystem.robot(duration=3)\n",
    "rb.switch_to_customizedPose(defaultPose.prototypeFacialExpressions['surprise'])\n",
    "rb.connect_ros(True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8f8efeb-d371-41d9-a82d-ebd89e2f6817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize_robotParams\n",
      "\n",
      "\n",
      "Smoothly execution activated\n",
      "return_to_stable_state, self.robotParams are all set\n",
      "self.lastState [64, 64, 128, 128, 128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 128, 128, 128, 0]\n",
      "self.nextState [86, 86, 128, 128, 128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 122]\n",
      "Smoothly execution activated\n"
     ]
    }
   ],
   "source": [
    "# Return to StandardPose\n",
    "import RCSystem\n",
    "\n",
    "rb = RCSystem.robot(duration=3)\n",
    "rb.switch_to_customizedPose(rb.AUPose['StandardPose'])\n",
    "rb.connect_ros(True, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ae01804-6452-49db-a6c3-5aef708d8b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize_robotParams\n",
      "\n",
      "\n",
      "Smoothly execution activated\n",
      "return_to_stable_state, self.robotParams are all set\n",
      "self.lastState [64, 64, 128, 128, 128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 128, 128, 128, 0]\n",
      "self.nextState [86, 86, 128, 128, 128, 187, 187, 0, 0, 0, 96, 0, 0, 0, 242, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 122]\n",
      "Smoothly execution activated\n"
     ]
    }
   ],
   "source": [
    "# Return to StandardPose\n",
    "import RCSystem\n",
    "\n",
    "rb = RCSystem.robot(duration=3)\n",
    "# rb.switch_to_customizedPose(rb.AUPose['StandardPose'])\n",
    "# rb.connect_ros(True, False)\n",
    "\n",
    "rb.switch_to_customizedPose([86, 86, 128, 128, 128, 187, 187, 0, 0, 0, 96, 0, 0, 0, 242, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 122])\n",
    "rb.connect_ros(True, False)\n",
    "import time\n",
    "time.sleep(3)\n",
    "\n",
    "# rb.switch_to_customizedPose(rb.AUPose['StandardPose'])\n",
    "# rb.connect_ros(True, False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb89f08b-9db9-4aba-af8d-4a762b9ee4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import defaultPose\n",
    "import numpy as np\n",
    "neutral_baseline = defaultPose.prototypeFacialExpressions[\"netural\"]\n",
    "baseline = defaultPose.prototypeFacialExpressions[\"happiness\"]\n",
    "\n",
    "subtract = abs(np.array(neutral_baseline) - np.array(baseline))\n",
    "axes = {}\n",
    "for i in range(len(subtract)):\n",
    "    if subtract[i] != 0:\n",
    "        axes[\"x{}\".format(i+1)] = subtract[i]\n",
    "print(axes)\n",
    "\n",
    "subtract = abs(np.array(defaultPose.prototypeFacialExpressions[\"happiness\"]) - np.array(defaultPose.hotExpressions[\"hotHappiness\"]))\n",
    "print(subtract)\n",
    "axes = {}\n",
    "for i in range(len(subtract)):\n",
    "    if subtract[i] != 0:\n",
    "        axes[\"x{}\".format(i+1)] = subtract[i]\n",
    "print(axes)\n",
    "# anger [1, 2, 6, 7, 11, 15]\n",
    "# Happiness[6, 7, 9, 13, 16, 17, 18, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d390658f-3dd6-4d82-b77a-0d0524e80fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import RCSystem\n",
    "import defaultPose\n",
    "import copy\n",
    "import time\n",
    "\n",
    "# -----------------------\n",
    "# 211126\n",
    "# happiness\n",
    "emo_name = 'happiness'\n",
    "final_iter = 5\n",
    "total_iter = 30\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 211122\n",
    "# Anger\n",
    "# Best \n",
    "# Final_result = {'target': 0.018799269571900368, 'params': {'x11': 41.000005745751935, 'x15': 101.75836276831566, 'x6': 22.061358723618913}}\n",
    "\n",
    "# Happiness\n",
    "# Best # 22\n",
    "# [86, 86, 128, 128, 128, 62, 62, 0, 253, 0, 0, 0, 253, 0, 0, 172, 172, 127, 0, 0, 0, 127, 0, 0, 0, 0, 0, 141, 69, 0, 0, 84, 128, 128, 122]\n",
    "# Final_result = {'target': 0.8695987462997437, 'params': {'x16': 171.59800310665995, 'x18': 126.68641049639601, 'x28': 141.1315389891181, 'x29': 68.71561151609762, 'x32': 84.15255955995656, 'x6': 62.45892190919146, 'x9': 252.7459651617753}}\n",
    "# ----------------------\n",
    "\n",
    "neutral = [86, 86, 128, 128, 128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 122]\n",
    "finalResult = copy.copy(neutral)\n",
    "final_name = emo_name + '_final_{}_{}'.format(final_iter, total_iter)\n",
    "for k,v in Final_result[\"params\"].items():\n",
    "        # print(k,v)\n",
    "        if \"x\" in k:\n",
    "            finalResult[int(k[1:])-1] = round(v)\n",
    "# x2 = x1, use one axis for eyes upper lid\n",
    "finalResult[1] = finalResult[0]\n",
    "# x7 = x6, use one axis for eyes lower lid\n",
    "finalResult[6] = finalResult[5]\n",
    "# x13 = x9\n",
    "finalResult[12] = finalResult[8]\n",
    "# x17 = x16\n",
    "finalResult[16] = finalResult[15]\n",
    "# x22 = x18\n",
    "finalResult[21] = finalResult[17]\n",
    "print(finalResult)\n",
    "finalResult = RCSystem.checkParameters(finalResult)\n",
    "\n",
    "rb = RCSystem.robot(duration=2\n",
    "rb.switch_to_customizedPose(finalResult)\n",
    "rb.connect_ros(isSmoothly=True, isRecording=False) # isSmoothly = True ,isRecording = True\n",
    "\n",
    "time.sleep(3)\n",
    "rb.take_picture(isUsingCounter=False, appendix=emo_name, folder='')\n",
    "print(\"pyfeat result: \", RCSystem.py_feat_analysis(img=rb.fileName, target_emotion=\"happiness\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6900be64-5fc5-4550-a49f-d46f7e6d274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral = [86, 86, 128, 128, 128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 122]\n",
    "finalResult = copy.copy(neutral)\n",
    "for k,v in Final_result[\"params\"].items():\n",
    "        # print(k,v)\n",
    "        if \"x\" in k:\n",
    "            finalResult[int(k[1:])-1] = round(v)\n",
    "finalResult[1] = finalResult[0]\n",
    "finalResult[6] = finalResult[5]\n",
    "# print(finalResult)\n",
    "finalResult = RCSystem.checkParameters(finalResult)\n",
    "\n",
    "rb = RCSystem.robot(duration=3)\n",
    "rb.switch_to_customizedPose(finalResult)\n",
    "rb.connect_ros(isSmoothly=True, isRecording=False) # isSmoothly = True ,isRecording = True\n",
    "time.sleep(3)\n",
    "rb.take_picture(isUsingCounter=False, appendix='_test')\n",
    "print(\"pyfeat result: \", RCSystem.py_feat_analysis(img=rb.fileName, target_emotion=\"Happiness\"))\n",
    "\n",
    "# time.sleep(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d18ba-27c8-497f-be55-5b31a2a77ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard angry\n",
    "rb.switch_to_customizedPose(defaultPose.prototypeFacialExpressions[\"happiness\"])\n",
    "rb.connect_ros(isSmoothly=True, isRecording=False) # isSmoothly = True ,isRecording = True\n",
    "time.sleep(3)\n",
    "rb.take_picture(isUsingCounter=False, appendix='prototypehappiness_test')\n",
    "print(\"pyfeat result: \", RCSystem.py_feat_analysis(img=rb.fileName, target_emotion=\"Happiness\"))\n",
    "\n",
    "rb.switch_to_customizedPose(rb.AUPose['StandardPose'])\n",
    "rb.connect_ros(True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30301a-f085-4c77-8e07-d75691dbf134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import RCSystem\n",
    "import defaultPose\n",
    "import time\n",
    "rb = RCSystem.robot(duration=2)\n",
    "\n",
    "rb.switch_to_customizedPose(defaultPose.prototypeFacialExpressions[\"happiness\"])\n",
    "rb.connect_ros(True, False)\n",
    "time.sleep(2)\n",
    "rb.take_picture(isUsingCounter=False, appendix='prototypehappiness_test')\n",
    "print(\"pyfeat result: \", RCSystem.py_feat_analysis(img=rb.fileName, target_emotion=\"Happiness\"))\n",
    "\n",
    "time.sleep(3)\n",
    "rb.switch_to_customizedPose(defaultPose.hotExpressions[\"hotHappiness\"])\n",
    "rb.connect_ros(True, False)\n",
    "time.sleep(2)\n",
    "rb.take_picture(isUsingCounter=False, appendix='prototypehappiness_test')\n",
    "print(\"pyfeat result: \", RCSystem.py_feat_analysis(img=rb.fileName, target_emotion=\"Happiness\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfd8d0c-8306-4801-ba8e-2f611cef33cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [49, 49, 128, 128, 128, 196, 196, 0, 0, 0, 158, 0, 0, 0, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 122]\n",
    "# a = [216, 216, 128, 128, 128, 138, 138, 0, 0, 0, 183, 0, 0, 0, 75, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 122]\n",
    "a = [198, 198, 128, 128, 128, 95, 95, 0, 0, 0, 225, 0, 0, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 122]\n",
    "print(a)\n",
    "# a = copy.copy(rb.AUPose['StandardPose'])\n",
    "# a[15],a[16] = 200,200\n",
    "# a[17]=100\n",
    "# a[21]=a[17]\n",
    "# a[27]=100\n",
    "# a[31]=200\n",
    "rb.switch_to_customizedPose(a)\n",
    "rb.connect_ros(True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82670c9-daab-45af-98e7-b9ad4560dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import RCSystem\n",
    "\n",
    "rb = RCSystem.robot(duration=3)\n",
    "rb.switch_to_customizedPose(rb.AUPose['StandardPose'])\n",
    "rb.connect_ros(True, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c770a6c-48ca-4127-a4d6-e8f3f8858cef",
   "metadata": {},
   "source": [
    "# Only Pyfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911340f3-caa0-429e-a938-6061e1fcee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human pyfeat\n",
    "\n",
    "import RCSystem\n",
    "from feat import Detector\n",
    "face_model = \"retinaface\"\n",
    "landmark_model = \"mobilenet\"\n",
    "au_model = \"rf\"\n",
    "emotion_model = \"resmasknet\"\n",
    "detector = Detector(face_model = face_model, landmark_model = landmark_model, au_model = au_model, emotion_model = emotion_model)\n",
    "\n",
    "image_prediction = detector.detect_image(\"image_analysis/temp/anger_human2.jpeg\")\n",
    "df = image_prediction.head()\n",
    "print(df.iloc[:, -8:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c9df04-28b7-4416-a251-ad6b766e068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surprise pyfeat\n",
    "\n",
    "import RCSystem\n",
    "from feat import Detector\n",
    "import os\n",
    "face_model = \"retinaface\"\n",
    "landmark_model = \"mobilenet\"\n",
    "au_model = \"rf\"\n",
    "emotion_model = \"resmasknet\"\n",
    "detector = Detector(face_model = face_model, landmark_model = landmark_model, au_model = au_model, emotion_model = emotion_model)\n",
    "\n",
    "# Surprise\n",
    "target_emotion = 'surprise'\n",
    "folderName = \"image_analysis/211126Exp/Exp1/surprise_1/\"\n",
    "ls_name = os.listdir(folderName)\n",
    "print(ls_name)\n",
    "result_dic = {}\n",
    "# image_prediction = detector.detect_image('image_analysis/211126Exp/Exp1/surprise_1/2021_11_26_15_09_48_surprise_215.png')\n",
    "# df = image_prediction.head()\n",
    "# targetID = RCSystem.get_target(target_emotion)\n",
    "# temp = df.iloc[:, -8:].iloc[0, targetID]\n",
    "\n",
    "# print(temp)\n",
    "for i in ls_name:\n",
    "#     try:\n",
    "    print(folderName + i)\n",
    "    image_prediction = detector.detect_image(folderName + i)\n",
    "    df = image_prediction.head()\n",
    "    targetID = RCSystem.get_target(target_emotion)\n",
    "    temp = df.iloc[:, -8:].iloc[0, targetID]\n",
    "    result_dic[i[:-4]] = temp\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d121176-7408-43d9-b51c-4a8f24aecfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in result_dic:\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f33b36-89f0-4600-9792-c4533d4fc14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp pyfeat\n",
    "\n",
    "import RCSystem\n",
    "from feat import Detector\n",
    "face_model = \"retinaface\"\n",
    "landmark_model = \"mobilenet\"\n",
    "au_model = \"rf\"\n",
    "emotion_model = \"resmasknet\"\n",
    "detector = Detector(face_model = face_model, landmark_model = landmark_model, au_model = au_model, emotion_model = emotion_model)\n",
    "\n",
    "# Anger\n",
    "image_prediction = detector.detect_image(\"image_analysis/temp/2021_11_26_15_05_49_happiness_172.png\")\n",
    "df = image_prediction.head()\n",
    "print(df.iloc[:, -8:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018d640d-e4eb-4541-ae5d-03f683547bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b0dc98-803c-49d5-9718-a2d1aad3fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from feat import Fex\n",
    "# fex = Fex()\n",
    "\n",
    "# from feat import Detector\n",
    "# detector = Detector()\n",
    "\n",
    "from feat import Detector\n",
    "face_model = \"retinaface\"\n",
    "landmark_model = \"mobilenet\"\n",
    "au_model = \"rf\"\n",
    "emotion_model = \"resmasknet\"\n",
    "detector = Detector(face_model = face_model, landmark_model = landmark_model, au_model = au_model, emotion_model = emotion_model)\n",
    "\n",
    "# image prediction\n",
    "# for i in [\"happyness\", \"sadness\", \"surprise\"]:\n",
    "# for i in [\"anger\", \"disgust\", \"fear\"]:\n",
    "#     image_prediction = detector.detect_image(i + \".png\")\n",
    "#     image_prediction.plot_detections()\n",
    "\n",
    "# video prediction\n",
    "import os\n",
    "filePath = \"../Study3/\"\n",
    "videoNames = os.listdir(filePath)\n",
    "flag = 0\n",
    "for i in videoNames:\n",
    "    if flag < 1:\n",
    "        tempVideoPath = os.path.join(filePath, i)\n",
    "        print(tempVideoPath)\n",
    "        # video_prediction = detector.detect_video(tempVideoPath, skip_frames=0)\n",
    "        video_prediction = detector.detect_video(tempVideoPath)\n",
    "        video_prediction.emotions().plot()\n",
    "        print(video_prediction.head())\n",
    "\n",
    "        flag += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b3561-92d7-4084-9749-f2c39500fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feat import Detector\n",
    "face_model = \"retinaface\"\n",
    "landmark_model = \"mobilenet\"\n",
    "au_model = \"rf\"\n",
    "emotion_model = \"resmasknet\"\n",
    "detector = Detector(face_model = face_model, landmark_model = landmark_model, au_model = au_model, emotion_model = emotion_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3cb40d-4401-4909-b79d-aa38bba3b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image prediction\n",
    "\n",
    "for i in [\"anger\", \"disgust\", \"fear\", \"happyness\", \"sadness\", \"surprise\"]:\n",
    "#     image_prediction = detector.detect_image(i + \".png\")\n",
    "#     image_prediction.head()\n",
    "    image_prediction = detector.detect_image(\"Study2/\" + i + \".png\")\n",
    "    df = image_prediction.head()\n",
    "    print(df.iloc[:, -8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec116e4-e03f-424b-8359-8f41b3c99b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "for i in range(1, 36):\n",
    "    name.append('x{}'.format(i))\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eb8308-603f-4ada-95a4-db875bd63467",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b1a318-01ed-4523-ad2d-9be1948ab04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from defaultPose import prototypeFacialExpressions as proto\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "ne = np.array(proto['netural'])\n",
    "an = np.array(proto['anger'])\n",
    "di = np.array(proto['disgust'])\n",
    "fe = np.array(proto['fear'])\n",
    "ha = np.array(proto['happiness'])\n",
    "sa = np.array(proto['sadness'])\n",
    "su = np.array(proto['surprise'])\n",
    "\n",
    "dif = np.array([ne, an, di, fe, ha, sa, su]) - ne\n",
    "dif = abs(dif)\n",
    "dif = np.int64(dif>0)\n",
    "print(dif)\n",
    "\n",
    "# background\n",
    "# ---------------\n",
    "from matplotlib.pyplot import figure\n",
    "fig, ax = plt.subplots(figsize=(30,5)) # set figure size\n",
    "fig.set_facecolor('white') # set background color\n",
    "# ---------------\n",
    "\n",
    "\n",
    "sn.heatmap(dif, cmap=\"inferno\", fmt = 'd', linewidth = 2, yticklabels=['neutral', \"anger\", \"disgust\", \"fear\", \"happyness\", \"sadness\", \"surprise\"],\n",
    "          xticklabels=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20', 'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30', 'x31', 'x32', 'x33', 'x34', 'x35'])\n",
    "# plt.show()\n",
    "fig.savefig(\"emotion_to_actuators.png\", format=\"png\", dpi=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a94a7-db05-471b-b0f8-289322ce6aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"db_confussion_raw_study2.csv\")\n",
    "\n",
    "y_pred = df.iloc[:, 3:]\n",
    "print(y_pred.shape)\n",
    "y_actual=np.array([0,1,2,3,4,5,0,1,2,3,4,5])\n",
    "temp = np.array([0,1,2,3,4,5,0,1,2,3,4,5])\n",
    "for i in range(29):\n",
    "    temp = np.vstack([temp, y_actual])\n",
    "\n",
    "y_actual = temp\n",
    "\n",
    "# confusion matrix function receive one dimension vector\n",
    "y_pred = np.array(df.iloc[:, 3:]).flatten()\n",
    "y_actual = np.array(y_actual).flatten()\n",
    "\n",
    "# background\n",
    "# ---------------\n",
    "from matplotlib.pyplot import figure\n",
    "fig, ax = plt.subplots(figsize=(10,8)) # set figure size\n",
    "fig.set_facecolor('white') # set background color\n",
    "# ---------------\n",
    "\n",
    "def switch_to_Emotion(x):\n",
    "    if x == 0:\n",
    "        return \"Anger\"\n",
    "    elif x == 1:\n",
    "        return \"Disgust\"\n",
    "    elif x == 2:\n",
    "        return \"Fear\"\n",
    "    elif x == 3:\n",
    "        return \"Happiness\"\n",
    "    elif x == 4:\n",
    "        return \"Sadness\"\n",
    "    elif x == 5:\n",
    "        return \"Surprise\"\n",
    "    else:\n",
    "        raise Error\n",
    "y_emo_pred = []\n",
    "y_emo_actual = []\n",
    "\n",
    "for i in range(y_pred.shape[0]):\n",
    "    y_emo_pred.append(switch_to_Emotion(y_pred[i]))\n",
    "    y_emo_actual.append(switch_to_Emotion(y_actual[i]))\n",
    "\n",
    "# print(y_actual)\n",
    "# print(y_pred)\n",
    "\n",
    "data = {'y_Actual':    y_emo_pred,\n",
    "        'y_Predicted': y_emo_actual\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "print(df)\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted']) / 60 # proportion\n",
    "# confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'], margins = True)\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "plt.show()\n",
    "# fig.savefig(\"confusionmatrix_proportion.png\", format=\"png\", dpi=300)\n",
    "# fig.savefig(\"confusionmatrix_proportion.eps\", format=\"eps\")\n",
    "\n",
    "\n",
    "# confusion matrix with sklearn\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# confusion_matrix = confusion_matrix(y_actual, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06afdc6-ef1a-44bd-8efb-3bed8ffdc61b",
   "metadata": {},
   "source": [
    "# Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c48c8-abb5-4c1e-8449-787eaa3085cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corr matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "df = pd.read_csv(\"db_raw_study2.csv\")\n",
    "df = df.iloc[:, 3:]\n",
    "\n",
    "corrMatrix = df.corr()\n",
    "\n",
    "# background\n",
    "# ---------------\n",
    "from matplotlib.pyplot import figure\n",
    "fig, ax = plt.subplots(figsize=(10,8)) # set figure size\n",
    "fig.set_facecolor('white') # set background color\n",
    "# ---------------\n",
    "\n",
    "sn.heatmap(corrMatrix, annot = True) # generate heatmap\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"correlationmatrix.png\", format=\"png\", dpi=300)\n",
    "fig.savefig(\"correlationmatrix.eps\", format=\"eps\")\n",
    "\n",
    "\n",
    "# consistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a3944b-33ef-4f8c-baa4-c6b60c0737e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corr matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "df = pd.read_csv(\"db_raw_study2.csv\")\n",
    "df = df.iloc[:, 3:]\n",
    "\n",
    "corrMatrix = df.corr()\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "fig, ax = plt.subplots(figsize=(10,8)) # set figure size\n",
    "fig.set_facecolor('white') # set background color\n",
    "sn.heatmap(corrMatrix, annot = True) # generate heatmap\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da29b184-137e-4d66-a2f3-f3a6a7d034e3",
   "metadata": {},
   "source": [
    "# LOG cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9480714-852f-4e7b-ad9d-9218c759682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "lineList = []\n",
    "pattern='^Using downloaded|^Loading Face Detection|^Input|N/A|^/home/dongagent/anaconda3/lib/python3.8|built|configuration'\n",
    "pattern+='|^  lib|Stream|Metadata|encoder|Press|Loading'\n",
    "matchPattern = re.compile(pattern)\n",
    "file = open('output.log', 'r')\n",
    "while 1:\n",
    "    line = file.readline()\n",
    "    if not line:\n",
    "        print(\"Read file End or Error\")\n",
    "        break\n",
    "    elif matchPattern.search(line):\n",
    "        print('matched!')\n",
    "        pass\n",
    "    else:\n",
    "        lineList.append(line)\n",
    "file.close()\n",
    "file = open(r'target.txt', 'w',encoding='UTF-8')\n",
    "for i in lineList:\n",
    "    file.write(i)\n",
    "file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c65f9-621c-4d2e-9096-66b582608d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('target.txt', 'r')\n",
    "line = file.readline()\n",
    "print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
