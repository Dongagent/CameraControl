{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c0f2c42-5240-4843-8f9b-160a7021a428",
   "metadata": {},
   "source": [
    "# show the max and min in each emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e22af3-2ad7-493f-bb95-cf69fdc228cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "emolist = 'anger, disgust, fear, happiness, sadness, surprise'.split(', ')\n",
    "result = {x:[] for x in emolist}\n",
    "myfolder = 'image_analysis/Exp_collections/230210Exp13Lighting_sys_500/'\n",
    "\n",
    "for CURR_EMO in emolist:\n",
    "#     CURR_EMO = 'anger'\n",
    "    images = [x for x in os.listdir(os.path.join(myfolder, CURR_EMO)) if 'png' in x]\n",
    "\n",
    "    for img in images:\n",
    "        test = os.path.join(myfolder, CURR_EMO, img)\n",
    "        csvname = test.split('.png')[0] + '_emotion.csv'\n",
    "        tmp = pd.read_csv(csvname)\n",
    "        result[CURR_EMO].append(float(tmp[CURR_EMO]))\n",
    "\n",
    "    print(CURR_EMO)\n",
    "    print(f'max: {max(result[CURR_EMO])}')\n",
    "    print(f'min: {min(result[CURR_EMO])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc0513-4c05-47f6-be22-3752bbf33d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for each emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac4e015-90e5-49b2-9a6f-2915dbc6752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708bf37-00d8-411e-b820-840bb058720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "float(tmp[CURR_EMO])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ce39d-d87a-410a-9c65-b90c574ccdba",
   "metadata": {},
   "source": [
    "# Model range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a174f12-6be8-4628-a3cc-d6543b21cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from intensityNet import * \n",
    "global intensityModel\n",
    "intensityModel = ''\n",
    "\n",
    "def intensityNet_analysis(img, target_emotion, is_save_csv=True):\n",
    "    # remember to set it before doing analysis\n",
    "\n",
    "    global intensityModel\n",
    "    # use intensityModel to detect emo\n",
    "    detection_res = intensityModel.detect_emo(Image.open(img))\n",
    "    detection_res = detection_res.tolist()\n",
    "    output = detection_res[get_target(target_emotion)]\n",
    "\n",
    "#     # create a pd dataframe\n",
    "#     detection_res = pd.DataFrame([detection_res], columns=[\"angry\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"])\n",
    "#     # Create DataFrame\n",
    "\n",
    "#     if is_save_csv:\n",
    "#         csv_emotion_name = img[:-4]+\"_intensitynet.csv\"\n",
    "#         detection_res.to_csv(csv_emotion_name)\n",
    "\n",
    "    # result = tmp_res[target_emotion]\n",
    "    return output\n",
    "\n",
    "def setIntensityModel(target_emotion):\n",
    "    global intensityModel\n",
    "    # Load the model\n",
    "    # ['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise']\n",
    "    print(\"target_emotion:\", target_emotion)\n",
    "    if target_emotion.lower() in [\"anger\", 'angry']:\n",
    "        model_path = \"new_models/angry_fold3_epoch7.pt\"\n",
    "    elif target_emotion.lower() in [\"disgust\"]:\n",
    "        model_path = \"new_models/disgust_fold3_epoch7.pt\"\n",
    "    elif target_emotion.lower() in [\"fear\"]:\n",
    "        model_path = \"new_models/fear_fold3_epoch6.pt\"\n",
    "    elif target_emotion.lower() in [\"happiness\", \"happy\"]:\n",
    "        model_path = \"new_models/happy_fold2_epoch7.pt\"\n",
    "    elif target_emotion.lower() in [\"sadness\", \"sad\"]:\n",
    "        model_path = \"new_models/sad_fold2_epoch6.pt\"\n",
    "    elif target_emotion.lower() in [\"surprise\"]:\n",
    "        model_path = \"new_models/surprise_fold3_epoch5.pt\"\n",
    "    else:\n",
    "        model_path = \"\"\n",
    "\n",
    "    intensityModel = IntensityNet_type1(model_path)\n",
    "    return 1\n",
    "\n",
    "# intensityNet_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3624bd-cb4a-4424-9ce2-f56e5305c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "emolist = 'anger, disgust, fear, happiness, sadness, surprise'.split(', ')\n",
    "result = {x:[] for x in emolist}\n",
    "myfolder = 'image_analysis/Exp_collections/230210Exp13Lighting_sys_500/'\n",
    "\n",
    "\n",
    "# CURR_EMO = 'anger'\n",
    "\n",
    "global intensityModel\n",
    "intensityModel = ''\n",
    "\n",
    "\n",
    "\n",
    "for CURR_EMO in emolist:\n",
    "    setIntensityModel(CURR_EMO)\n",
    "    images = [x for x in os.listdir(os.path.join(myfolder, CURR_EMO)) if 'png' in x]\n",
    "    \n",
    "    for i in images:\n",
    "        result[CURR_EMO].append(intensityNet_analysis(os.path.join(myfolder, CURR_EMO, images[0]), CURR_EMO))\n",
    "        \n",
    "    print(CURR_EMO)\n",
    "    print(len(result[CURR_EMO]))\n",
    "    print(f'max: {max(result[CURR_EMO])}')\n",
    "    print(f'min: {min(result[CURR_EMO])}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94237e0b-b98e-4bc5-9538-90e35b203f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the mixed model\n",
    "\n",
    "# Function to calculate the mixed output with nonlinear transition using a sigmoid function\n",
    "def calculate_output_nonlinear(A, B, threshold=0.75, alpha=0.8, B_min=0.39, B_max=0.64, output_min=0.75, output_max=1.2, k=10):\n",
    "    \"\"\"\n",
    "    Calculate the mixed output based on values of A and B, with a threshold-based decision rule.\n",
    "    \n",
    "    Parameters:\n",
    "    A (float): Value from distribution A.\n",
    "    B (float): Value from distribution B.\n",
    "    threshold (float): Threshold for A to determine when to mix. Default is 0.75.\n",
    "    alpha (float): Weighting factor for B' in the mix when A > threshold. Default is 0.8.\n",
    "    B_min (float): Minimum value of B's original range. Default is 0.39.\n",
    "    B_max (float): Maximum value of B's original range. Default is 0.64.\n",
    "    output_min (float): Minimum value of the target range for B' (after scaling). Default is 0.75.\n",
    "    output_max (float): Maximum value of the target range for B' (after scaling). Default is 1.2.\n",
    "\n",
    "    Returns:\n",
    "    float: Final output value based on A and B.\n",
    "    \"\"\"\n",
    "        \n",
    "    # If A is below or equal to the threshold, output A directly\n",
    "    if A <= threshold:\n",
    "        return A\n",
    "    \n",
    "    # Scale B to fit within the desired range [output_min, output_max]\n",
    "    B_mapped = output_min + (B - B_min) * (output_max - output_min) / (B_max - B_min)\n",
    "    \n",
    "    # Apply a sigmoid-based weight for smooth transition\n",
    "    weight = 1 / (1 + np.exp(-k * (A - threshold)))  # Sigmoid function for smoother blending\n",
    "    \n",
    "    # Calculate the smooth nonlinear mixed output\n",
    "    output = weight * (alpha * B_mapped + (1 - alpha) * A) + (1 - weight) * A\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dad58e-cd47-4f37-9c04-6173c930e5d2",
   "metadata": {},
   "source": [
    "## Test the mixed model on old dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb527801-c23e-451a-960d-1c3b323c5761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dad05b0-2cb5-49da-8704-72b7853cae76",
   "metadata": {},
   "source": [
    "# extract probe from past experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b5cdb-3389-45f0-bdd2-8c9b12e96f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def omega(x):\n",
    "    return 1.0 / (1 + np.exp(-k * ( x - threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379dd81b-930c-4dca-a38a-fc400400e9d3",
   "metadata": {},
   "source": [
    "# difference between pyfeat value and resmasknet value (DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388f01d-a9bc-451d-9fdf-1b77009565ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyfeat value\n",
    "from feat import Detector\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "# from SiameseRankNet import *\n",
    "from resmasknet import ResMaskNet\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "detector = Detector(emotion_model = \"resmasknet\", landmark_model='mobilefacenet')\n",
    "\n",
    "def get_face_box(start_x, start_y, end_x, end_y):\n",
    "    center_x, center_y = (start_x + end_x) // 2, (start_y + end_y) // 2\n",
    "    square_length = ((end_x - start_x) + (end_y - start_y)) // 2 // 2\n",
    "    square_length *= 1.1\n",
    "    start_x = int(center_x - square_length)\n",
    "    start_y = int(center_y - square_length)\n",
    "    end_x = int(center_x + square_length)\n",
    "    end_y = int(center_y + square_length)\n",
    "    return start_x, start_y, end_x, end_y\n",
    "\n",
    "\n",
    "result = {}\n",
    "myfolder = 'image_analysis/'\n",
    "CURR_EMO = 'anger'\n",
    "images = [x for x in os.listdir(os.path.join(myfolder, CURR_EMO)) if 'png' in x]\n",
    "image_size = (224, 224)\n",
    "transform = transforms.Compose(\n",
    "            [transforms.ToPILImage(), transforms.ToTensor()]\n",
    "        )\n",
    "model = ResMaskNet()\n",
    "for i in images[:]:\n",
    "    print(i)\n",
    "    test = os.path.join(myfolder, CURR_EMO, i)\n",
    "    res = detector.detect_image(test)\n",
    "    facebox = res.iloc[:,1:5]\n",
    "    emotions = res.iloc[:, -8:]\n",
    "    print(f'use pyfeat:\\n{[round(x, 5) for x in np.array(emotions.iloc[:, :]).tolist()[0][:-1]]}')\n",
    "    \n",
    "    frame = cv2.imread(test)\n",
    "    face = detector.detect_faces(frame)[0][:4]\n",
    "    emotion = model.detect_emo(frame=frame, detected_face=[face])\n",
    "    print(emotion)\n",
    "    print(f'use model directly:\\n{list(round(x, 5) for x in emotion[0].tolist())}')\n",
    "    \n",
    "    test = os.path.join(myfolder, CURR_EMO, i)\n",
    "    res = detector.detect_image(test)\n",
    "    facebox = res.iloc[:,1:5]\n",
    "    emotions = res.iloc[:, -8:]\n",
    "    print(f'use pyfeat again:\\n{[round(x, 5) for x in np.array(emotions.iloc[:, :]).tolist()[0][:-1]]}')\n",
    "    \n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab6b39f-c927-488d-b313-0bb7063b9b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c1ad93-37a8-4ef5-a294-cd1e3c76d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "new_df = pd.DataFrame(emotion, columns=[\"anger\", \"disgust\", \"fear\", \"happiness\", \"sadness\", \"surprise\", \"neutral\"])\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdd5c61-6f7a-4d6b-b83c-f093cc9ef1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ebdcc7-ba23-41fb-a9f7-86457be9c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from feat import Detector\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def get_target(emotion_name):\n",
    "    # Anger, Disgust, Fear, Happiness, Sadness, Surprise, Neutral\n",
    "    # or lowercase\n",
    "    if emotion_name in [\"Anger\", \"anger\"]:\n",
    "        return 0\n",
    "    elif emotion_name in [\"Disgust\", \"disgust\"]:\n",
    "        return 1\n",
    "    elif emotion_name in [\"Fear\", \"fear\"]:\n",
    "        return 2\n",
    "    elif emotion_name in [\"Happiness\", \"happiness\"]:\n",
    "        return 3\n",
    "    elif emotion_name in [\"Sadness\", \"sadness\"]:\n",
    "        return 4\n",
    "    elif emotion_name in [\"Surprise\", \"surprise\"]:\n",
    "        return 5\n",
    "    elif emotion_name in [\"Neutral\", \"neutral\"]:\n",
    "        return 6\n",
    "image_name = 'image_analysis/fear/2024_11_14_17_14_20_fear_0.png'\n",
    "target_emotion = 'disgust'\n",
    "\n",
    "facebox = detector.detect_faces(cv2.imread(image_name))[0]\n",
    "rmn_model = ResMaskNet()\n",
    "targetID = get_target(target_emotion)\n",
    "print(image_name)\n",
    "rmn_res = rmn_model.detect_emo(frame=cv2.imread(image_name), detected_face=[facebox])\n",
    "new_df = pd.DataFrame(rmn_res, columns=[\"anger\", \"disgust\", \"fear\", \"happiness\", \"sadness\", \"surprise\", \"neutral\"])\n",
    "new_df['input'] = image_name\n",
    "\n",
    "\n",
    "# -----------\n",
    "# old version\n",
    "# -----------\n",
    "image_prediction = detector.detect_image(image_name)\n",
    "df = image_prediction.head()\n",
    "\n",
    "targetID = get_target(target_emotion)\n",
    "\n",
    "assert list(new_df[target_emotion])[0] == list(df[target_emotion])[0], \"The result is not the same, old: {}, new: {}\".format(list(df[target_emotion])[0], list(new_df[target_emotion])[0])\n",
    "# return emo_df.iloc[0,targetID]\n",
    "print(new_df[target_emotion])\n",
    "print(df[target_emotion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8143d-788c-4e73-a748-a3fb2175fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(detector.detect_emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8937b5da-e26d-4c9f-8df5-4787940501ef",
   "metadata": {},
   "source": [
    "# test bayesian optimization using probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7092830-5274-43ef-b49f-e03ea43e6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "def generate_pbounds(axes, target_emotion):\n",
    "        pbounds_dic = {}\n",
    "        for i in axes:\n",
    "            if target_emotion == 'happiness' and i in [0, 1]:\n",
    "                # TODO need to verify\n",
    "                happy_upper = 120\n",
    "                pbounds_dic['x{}'.format(i)] = (0, happy_upper)\n",
    "            # elif i in [0, 1]:\n",
    "            #     pbounds_dic['x{}'.format(i)] = (0, 160)\n",
    "            # else:\n",
    "            pbounds_dic['x{}'.format(i)] = (0, 255)\n",
    "\n",
    "        # mouth\n",
    "        pbounds_dic['x32'] = (0, 110)\n",
    "\n",
    "        # dangerous point\n",
    "        pbounds_dic['x8'] = (-255, 255)\n",
    "        pbounds_dic['x18'] = (-255, 255)\n",
    "\n",
    "        print(pbounds_dic)\n",
    "        return pbounds_dic\n",
    "    \n",
    "target_emotion = 'target_emotion'\n",
    "all_axes_for_emotions = [1, 6, 8, 10, 11, 16, 18, 20, 28, 29, 30, 32]\n",
    "pbounds = generate_pbounds(all_axes_for_emotions, target_emotion)\n",
    "\n",
    "def middle_function(**kwargs):\n",
    "    print(kwargs)\n",
    "    return 'haha'\n",
    "\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "        f=middle_function,\n",
    "        # Define HyperParameter Space\n",
    "        # acquisition_function=acq,\n",
    "        pbounds = pbounds,\n",
    "        random_state=486,\n",
    "        verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823f9dca-a068-40ec-a337-dffa9f6e5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import UtilityFunction\n",
    "\n",
    "ucb = UtilityFunction(kind='ucb',\n",
    "                          kappa=2.576,\n",
    "                          xi=0.0,\n",
    "                          kappa_decay=1,\n",
    "                          kappa_decay_delay=0)\n",
    "suggest = optimizer.suggest(ucb)\n",
    "def check_suggestion(suggestion):\n",
    "    # x1 and x6\n",
    "    print('checked')\n",
    "    if suggestion['x1'] + suggestion['x6'] < 420:\n",
    "        # if the upper lid and lower lid are too close to each other, we should not return 0\n",
    "        print(\"[INFO]Eye closing Constraints, search another point\")\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "print(suggest)\n",
    "while not check_suggestion(suggest):\n",
    "    suggest = optimizer.suggest(ucb)\n",
    "if check_suggestion(suggest):\n",
    "    print('ok')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77caf3d8-29bc-4da4-a0ac-ff96824b90c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = optimizer.probe(ucb)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d064874c-60bd-469c-9e9b-1533961c33b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a944ba01-5b01-4cb5-8f3f-00b5aad6a7a1",
   "metadata": {},
   "source": [
    "# get prototype probe number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d7ca8ef-a63b-4127-a5a7-abd7df43c05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger [0, 0, 128, 128, 128, 255, 255, 0, 0, 0, 255, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 122]\n",
      "{'x1':0, 'x6':255, 'x8':0, 'x10':0, 'x11':255, 'x16':0, 'x18':0, 'x20':0, 'x28':0, 'x29':0, 'x30':0, 'x32':0}\n",
      "disgust [86, 86, 128, 128, 128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 128, 128, 122]\n",
      "{'x1':86, 'x6':0, 'x8':0, 'x10':0, 'x11':0, 'x16':0, 'x18':0, 'x20':0, 'x28':0, 'x29':0, 'x30':255, 'x32':0}\n",
      "fear [0, 0, 128, 128, 128, 0, 0, 255, 0, 255, 255, 255, 0, 255, 255, 0, 0, 0, 0, 255, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 122]\n",
      "{'x1':0, 'x6':0, 'x8':255, 'x10':255, 'x11':255, 'x16':0, 'x18':0, 'x20':255, 'x28':0, 'x29':0, 'x30':0, 'x32':0}\n",
      "happiness [86, 86, 128, 128, 128, 255, 255, 0, 255, 0, 0, 0, 255, 0, 0, 255, 255, 255, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 122]\n",
      "hi\n",
      "x8\n",
      "x9 255\n",
      "{'x1':86, 'x6':255, 'x8':-255, 'x10':0, 'x11':0, 'x16':255, 'x18':255, 'x20':0, 'x28':0, 'x29':0, 'x30':0, 'x32':0}\n",
      "sadness [86, 86, 128, 128, 128, 0, 0, 0, 0, 255, 255, 0, 0, 255, 255, 0, 0, 0, 255, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 122]\n",
      "hi\n",
      "x18\n",
      "x19 255\n",
      "{'x1':86, 'x6':0, 'x8':0, 'x10':255, 'x11':255, 'x16':0, 'x18':-255, 'x20':0, 'x28':0, 'x29':0, 'x30':0, 'x32':0}\n",
      "surprise [0, 0, 128, 128, 128, 0, 0, 255, 0, 128, 0, 255, 0, 128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 122]\n",
      "{'x1':0, 'x6':0, 'x8':255, 'x10':128, 'x11':0, 'x16':0, 'x18':0, 'x20':0, 'x28':0, 'x29':0, 'x30':0, 'x32':0}\n"
     ]
    }
   ],
   "source": [
    "def get_default_pose(param, pos):\n",
    "    res = {}\n",
    "    for p in pos:\n",
    "        res[f'x{p}'] = param[p - 1]\n",
    "        if p + 1 in [9, 13, 19, 23] and param[p - 1] == 0 and param[p] != 0:\n",
    "            print('hi')\n",
    "            print(f'x{p}')\n",
    "            print(f'x{p+1} {param[p]}')\n",
    "            res[f'x{p}'] = - param[p]\n",
    "            \n",
    "        # [8, 12, 18, 22]. If p > 0, we do nothing. If p < 0, [8, 12, 18, 22] = 0, [9, 13, 19, 23] = -p\n",
    "    \n",
    "    return res\n",
    "\n",
    "import defaultPose\n",
    "\n",
    "for exp in ['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise']:\n",
    "    target = defaultPose.prototypeFacialExpressions[exp]\n",
    "    print(exp, target)\n",
    "    res = get_default_pose(target, [1, 6, 8, 10, 11, 16, 18, 20, 28, 29, 30, 32])\n",
    "    probe = \"\"\n",
    "    for k, v in res.items():\n",
    "        probe += f\"'{k}':{v}, \"\n",
    "    print('{' + probe[:-2] + '}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d4bd5d-b890-4d73-9078-268f9af746aa",
   "metadata": {},
   "source": [
    "# get human average probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d92956-8a8f-4b57-abcf-d3b399a574e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['surprise_275.png', 'surprise_245.png', 'surprise_261.png', 'surprise_369.png', 'surprise_337.png', 'surprise_121.png', 'surprise_428.png', 'surprise_407.png', 'surprise_440.png', 'surprise_106.png']\n",
      "['surprise_275_axes_data.csv', 'surprise_245_axes_data.csv', 'surprise_261_axes_data.csv', 'surprise_369_axes_data.csv', 'surprise_337_axes_data.csv', 'surprise_121_axes_data.csv', 'surprise_428_axes_data.csv', 'surprise_407_axes_data.csv', 'surprise_440_axes_data.csv', 'surprise_106_axes_data.csv']\n",
      "['2023_02_10_18_49_17_surprise_275_axes_data.csv', '2023_02_10_18_48_09_surprise_245_axes_data.csv', '2023_02_10_18_48_46_surprise_261_axes_data.csv', '2023_02_10_18_52_52_surprise_369_axes_data.csv', '2023_02_10_18_51_36_surprise_337_axes_data.csv', '2023_02_10_18_43_32_surprise_121_axes_data.csv', '2023_02_10_18_55_17_surprise_428_axes_data.csv', '2023_02_10_18_54_24_surprise_407_axes_data.csv', '2023_02_10_18_55_47_surprise_440_axes_data.csv', '2023_02_10_18_43_00_surprise_106_axes_data.csv']\n"
     ]
    }
   ],
   "source": [
    "import human_data\n",
    "import os\n",
    "\n",
    "hd = human_data.average_human_order\n",
    "# print(hd)\n",
    "emo = 'surprise'\n",
    "emoo = emo\n",
    "# print(hd[emo][:10])\n",
    "\n",
    "tr = [emo + '_' + x.split('_')[1] for x in hd[emoo][:10]]\n",
    "print(tr)\n",
    "tr = [t.split('.png')[0] + '_axes_data.csv' for t in tr]\n",
    "print(tr)\n",
    "\n",
    "basefolder = 'image_analysis/Exp_collections/230210Exp13Lighting_sys_500/'\n",
    "files = os.listdir(os.path.join(basefolder, emo))\n",
    "\n",
    "def get_csv_name():\n",
    "    res = []\n",
    "    \n",
    "    for t in tr:\n",
    "        for file in files:\n",
    "            if t in file:\n",
    "                res.append(file)\n",
    "                continue\n",
    "\n",
    "    return res\n",
    "\n",
    "csvname = get_csv_name()\n",
    "print(csvname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d4672fc-c41a-4708-a376-fe800fed4122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'surprise': 'surprise_275_axes_data.csv', 'x1': 0, 'x10': 0, 'x11': 0, 'x16': 0, 'x18': 255, 'x19': 0, 'x20': 0, 'x28': 255, 'x29': 0, 'x30': 0, 'x32': 255, 'x6': 0, 'x8': 255, 'x9': 0}\n",
      "{'surprise': 'surprise_245_axes_data.csv', 'x1': 0, 'x10': 0, 'x11': 0, 'x16': 0, 'x18': 0, 'x19': 0, 'x20': 255, 'x28': 0, 'x29': 149, 'x30': 0, 'x32': 255, 'x6': 0, 'x8': 255, 'x9': 21}\n",
      "{'surprise': 'surprise_261_axes_data.csv', 'x1': 0, 'x10': 255, 'x11': 0, 'x16': 0, 'x18': 255, 'x19': 0, 'x20': 255, 'x28': 72, 'x29': 0, 'x30': 0, 'x32': 255, 'x6': 0, 'x8': 255, 'x9': 0}\n",
      "{'surprise': 'surprise_369_axes_data.csv', 'x1': 0, 'x10': 255, 'x11': 0, 'x16': 255, 'x18': 0, 'x19': 0, 'x20': 255, 'x28': 0, 'x29': 0, 'x30': 0, 'x32': 255, 'x6': 140, 'x8': 255, 'x9': 255}\n",
      "{'surprise': 'surprise_337_axes_data.csv', 'x1': 0, 'x10': 255, 'x11': 0, 'x16': 0, 'x18': 9, 'x19': 0, 'x20': 0, 'x28': 0, 'x29': 255, 'x30': 0, 'x32': 255, 'x6': 0, 'x8': 255, 'x9': 149}\n",
      "{'surprise': 'surprise_121_axes_data.csv', 'x1': 0, 'x10': 38, 'x11': 156, 'x16': 0, 'x18': 132, 'x19': 0, 'x20': 247, 'x28': 0, 'x29': 255, 'x30': 0, 'x32': 255, 'x6': 0, 'x8': 255, 'x9': 255}\n",
      "{'surprise': 'surprise_428_axes_data.csv', 'x1': 0, 'x10': 159, 'x11': 0, 'x16': 0, 'x18': 0, 'x19': 0, 'x20': 255, 'x28': 255, 'x29': 255, 'x30': 0, 'x32': 255, 'x6': 0, 'x8': 255, 'x9': 255}\n",
      "{'surprise': 'surprise_407_axes_data.csv', 'x1': 0, 'x10': 255, 'x11': 0, 'x16': 0, 'x18': 255, 'x19': 240, 'x20': 255, 'x28': 91, 'x29': 0, 'x30': 0, 'x32': 255, 'x6': 140, 'x8': 123, 'x9': 70}\n",
      "{'surprise': 'surprise_440_axes_data.csv', 'x1': 0, 'x10': 255, 'x11': 0, 'x16': 0, 'x18': 0, 'x19': 0, 'x20': 0, 'x28': 0, 'x29': 0, 'x30': 0, 'x32': 255, 'x6': 0, 'x8': 0, 'x9': 0}\n",
      "{'surprise': 'surprise_106_axes_data.csv', 'x1': 0, 'x10': 0, 'x11': 0, 'x16': 0, 'x18': 255, 'x19': 144, 'x20': 255, 'x28': 4, 'x29': 255, 'x30': 0, 'x32': 255, 'x6': 0, 'x8': 255, 'x9': 0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "for c in csvname:\n",
    "    tmp = pd.read_csv(os.path.join(basefolder, emo, c))\n",
    "    tmp = tmp.to_dict()\n",
    "    for k, v in tmp.items():\n",
    "        if 'x' in k:\n",
    "            tmp[k] = round(v[0])\n",
    "            \n",
    "    match = re.search(r\".*(surprise_\\d+_axes_data\\.csv)\", c)\n",
    "    tmp[emo] = match.group(1)\n",
    "    print()\n",
    "    print(tmp)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ab4fa4-ef0f-49ec-a1bc-43dec1ae0f4b",
   "metadata": {},
   "source": [
    "# get feat order probe as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed060ad1-3fc2-44cd-b012-ecd054e9e50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import human_data\n",
    "import os\n",
    "\n",
    "hd = human_data.feat_order\n",
    "# print(hd)\n",
    "emoo = 'angry'\n",
    "if emoo == 'angry':\n",
    "    emo = 'anger'\n",
    "elif emoo == 'happy':\n",
    "    emo = 'happiness'\n",
    "elif emoo == 'sad':\n",
    "    emo = 'sadness'\n",
    "else:\n",
    "    emo = emoo\n",
    "\n",
    "# print(hd[emo][:10])\n",
    "\n",
    "tr = [emo + '_' + x.split('_')[1] for x in hd[emoo][:10]]\n",
    "# print(tr)\n",
    "tr = [t.split('.png')[0] + '_axes_data.csv' for t in tr]\n",
    "print(tr)\n",
    "\n",
    "basefolder = 'image_analysis/Exp_collections/230210Exp13Lighting_sys_500/'\n",
    "files = os.listdir(os.path.join(basefolder, emo))\n",
    "\n",
    "def get_csv_name():\n",
    "    res = []\n",
    "    for t in tr:\n",
    "        for file in files:\n",
    "            if t in file:\n",
    "                res.append(file)\n",
    "                continue\n",
    "    return res\n",
    "\n",
    "csvname = get_csv_name()\n",
    "print(csvname)\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "for c in csvname:\n",
    "    tmp = pd.read_csv(os.path.join(basefolder, emo, c))\n",
    "    tmp = tmp.to_dict()\n",
    "#     print(tmp)\n",
    "    for k, v in tmp.items():\n",
    "        if 'x' in k:\n",
    "            tmp[k] = round(v[0])\n",
    "            \n",
    "    match = re.search(r\".*((anger|disgust|fear|happiness|sadness|surprise)_\\d+_axes_data\\.csv)\", c)\n",
    "    tmp[emo] = match.group(1)\n",
    "    print(tmp[emo])\n",
    "    print({k:v for k, v in tmp.items() if 'x' in k})\n",
    "    print()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37pyfeat1",
   "language": "python",
   "name": "py37pyfeat1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
